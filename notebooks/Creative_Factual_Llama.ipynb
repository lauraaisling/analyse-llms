{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674f7fa3-69e5-4c92-9571-4ef1c45590b8",
   "metadata": {},
   "source": [
    "## Import stuff and load calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a600eb6f-7ee9-4dbb-9c04-e66a5c4b34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.append(f\"{os.path.dirname(os.getcwd())}/scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09aef15-e4b2-408f-abbc-d9069bdd450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from creative_and_factual_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d612cb38-4c36-4825-bc26-b9479b15b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from diversity_metrics.metrics.model_free_metrics import *\n",
    "from diversity_metrics.embeddings.models import *\n",
    "from diversity_metrics.metrics.generalized_diversity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087973c7-485b-4fb6-a491-b95cadc1fcbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llama2_results_5_words = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/llama2_results_5_words.npy\", allow_pickle=True).item()\n",
    "llama2_chat_results_5_words = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/llama2-chat_results_5_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_results_5_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b_results_5_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_sft_results_5_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-sft_results_5_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_dpo_results_5_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-dpo_results_5_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_ppo_results_5_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-ppo_results_5_words.npy\", allow_pickle=True).item()\n",
    "\n",
    "llama2_results_20_words = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/llama2_results_20_words.npy\", allow_pickle=True).item()\n",
    "llama2_chat_results_20_words = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/llama2-chat_results_20_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_results_20_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b_results_20_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_sft_results_20_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-sft_results_20_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_dpo_results_20_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-dpo_results_20_words.npy\", allow_pickle=True).item()\n",
    "# pythia_69b_ppo_results_20_words  = np.load(f\"{os.path.dirname(os.getcwd())}/results/creative_factual/pythia-6.9b-ppo_results_20_words.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01ae65-6dc1-4059-81ea-5ab90a2d692c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f4dc0-b037-4fb4-a028-3d74e20b8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [k / 10. for k in range(1, 16)]\n",
    "temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc74d9-1c38-453f-9fc7-e6b00be4bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def limit_num_words(sentence, max_num_words):\n",
    "    return \" \".join(sentence.split()[:max_num_words])\n",
    "\n",
    "\n",
    "def average_pairwise_jaccard(sentences, n=2):\n",
    "    return np.mean([pairwise_ngram(n, x, y) for x, y in combinations(sentences, 2)])\n",
    "\n",
    "def self_bleu_smooth(sentences):\n",
    "    '''\n",
    "    Calculates the Self-BLEU score for a collection of generated examples (https://arxiv.org/abs/1802.01886)\n",
    "    :param sentences: List of generated examples\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    scores = []\n",
    "    for i, hypothesis in enumerate(sentences):\n",
    "        hypothesis_split = hypothesis.strip().split()\n",
    "\n",
    "        references = [sentences[j].strip().split() for j in range(len(sentences)) if i != j]\n",
    "\n",
    "        scores.append(sentence_bleu(references, hypothesis_split, smoothing_function=SmoothingFunction().method1))\n",
    "\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "diversity_metrics = {\"selfBleuSmoothed\": self_bleu_smooth,\n",
    "                    \"average_pairwise_ncd\": lambda sentences: np.mean(get_pairwise_ncd(sentences)),\n",
    "                     \"average_pairwise_jaccard_2\": partial(average_pairwise_jaccard, n=2),\n",
    "                    \"average_pairwise_jaccard_3\": partial(average_pairwise_jaccard, n=3),\n",
    "                    \"average_pairwise_jaccard_4\": partial(average_pairwise_jaccard, n=4),\n",
    "                    \"avg_compression_ratio_full\": avg_compression_ratio_full,\n",
    "                    \"avg_compression_ratio_target\": avg_compression_ratio_target,\n",
    "                    \"cosine_similarity\": None # will be filled in later\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc05c53-e28b-4e24-acc6-8f595a69df7d",
   "metadata": {},
   "source": [
    "## Plot output diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d8c0e-8bc0-4e1e-a01d-231a4124465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_label = [\"Self Bleu Smoothed\", \"Self Bleu Smoothed\", \"Average Pairwise NCD\", \"Average Pairwise NCD\", \n",
    "               \"Average Pairwise Jaccard 2\", \"Average Pairwise Jaccard 2\", \"Average Pairwise Jaccard 3\", \n",
    "               \"Average Pairwise Jaccard 3\", \"Average Pairwise Jaccard 4\", \"Average Pairwise Jaccard 4\", \n",
    "               \"Average Compression Ratio Full\", \"Average Compression Ratio Full\",\"Average Compression Ratio Target\", \n",
    "               \"Average Compression Ratio Target\", \"Cosine Similarity\", \"Cosine Similarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cded4-e5f9-4132-9eee-2cefa49eccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_factual_full_f = f\"{os.path.dirname(os.getcwd())}/results/creative_factual_llama_full.png\"\n",
    "\n",
    "num_metrics = len(diversity_metrics.keys())\n",
    "fig, axes = plt.subplots(num_metrics, 2, figsize=(20, 5*num_metrics))\n",
    "# make font bigger\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "text_effect = [path_effects.withStroke(linewidth=3, foreground='white')]\n",
    "\n",
    "i=0\n",
    "for index, metric in enumerate(diversity_metrics.keys()):\n",
    "\n",
    "    for col_idx, result_chat in enumerate([llama2_chat_results_20_words, llama2_chat_results_5_words]):\n",
    "        ax = axes[index, col_idx]\n",
    "\n",
    "        scores_factual_chat = result_chat[\"factual\"][metric]\n",
    "        scores_creative_chat = result_chat[\"creative\"][metric]\n",
    "\n",
    "        result_plm = [llama2_results_20_words, llama2_results_5_words][col_idx]\n",
    "        scores_factual_plm = result_plm[\"factual\"][metric]\n",
    "        scores_creative_plm = result_plm[\"creative\"][metric]\n",
    "\n",
    "        # Plotting for factual scores\n",
    "        ax.plot(temperatures, scores_factual_chat[:, :, 0].mean(axis=1), label='llama2-chat', marker='o', color=\"blue\")\n",
    "        ax.fill_between(temperatures, scores_factual_chat[:, :, 0].mean(axis=1) - 2 * scores_factual_chat[:, :, 0].std(axis=1) / np.sqrt(scores_factual_chat.shape[1]), \n",
    "                        scores_factual_chat[:, :, 0].mean(axis=1) + 2 * scores_factual_chat[:, :, 0].std(axis=1) / np.sqrt(scores_factual_chat.shape[1]), alpha=0.2, color=\"blue\")\n",
    "\n",
    "        ax.plot(temperatures, scores_factual_plm[:, :, 0].mean(axis=1), label='llama2', marker='o', color=\"red\")\n",
    "        ax.fill_between(temperatures, scores_factual_plm[:, :, 0].mean(axis=1) - 2 * scores_factual_plm[:, :, 0].std(axis=1) / np.sqrt(scores_factual_plm.shape[1]), \n",
    "                        scores_factual_plm[:, :, 0].mean(axis=1) + 2 * scores_factual_plm[:, :, 0].std(axis=1) / np.sqrt(scores_factual_plm.shape[1]), alpha=0.2, color=\"red\")\n",
    "\n",
    "        # Plotting for creative scores\n",
    "        ax.plot(temperatures, scores_creative_chat[:, :, 0].mean(axis=1), label='llama2-chat creative', marker='o', linestyle='--', color=\"lightblue\")\n",
    "        ax.fill_between(temperatures, scores_creative_chat[:, :, 0].mean(axis=1) - 2 * scores_creative_chat[:, :, 0].std(axis=1) / np.sqrt(scores_creative_chat.shape[1]), \n",
    "                        scores_creative_chat[:, :, 0].mean(axis=1) + 2 * scores_creative_chat[:, :, 0].std(axis=1) / np.sqrt(scores_creative_chat.shape[1]), alpha=0.2, color=\"lightblue\")\n",
    "\n",
    "        ax.plot(temperatures, scores_creative_plm[:, :, 0].mean(axis=1), label='llama2 creative', marker='o', linestyle='--', color=\"salmon\")\n",
    "        ax.fill_between(temperatures, scores_creative_plm[:, :, 0].mean(axis=1) - 2 * scores_creative_plm[:, :, 0].std(axis=1) / np.sqrt(scores_creative_plm.shape[1]), \n",
    "                        scores_creative_plm[:, :, 0].mean(axis=1) + 2 * scores_creative_plm[:, :, 0].std(axis=1) / np.sqrt(scores_creative_plm.shape[1]), alpha=0.2, color=\"salmon\")\n",
    "\n",
    "        ax.set_xlabel('Temperature')\n",
    "        # ax.set_ylabel(metric)\n",
    "        ax.set_ylabel(metric_label[i])\n",
    "        # ax.set_title(f'Diversity metric: {metric} for {20 if col_idx == 0 else 5} max words')\n",
    "        #ax.legend()\n",
    "        text_effect = [path_effects.withStroke(linewidth=3, foreground='white')]\n",
    "\n",
    "        # Add labels directly on the plot with white outline\n",
    "        end_temp = temperatures[-4]\n",
    "        text_factual1 = ax.text(end_temp, scores_factual_chat[:, :, 0].mean(axis=1)[-4], 'llama2-chat factual', color='blue', verticalalignment='bottom')\n",
    "        text_factual1.set_path_effects(text_effect)\n",
    "\n",
    "        text_factual2 = ax.text(end_temp, scores_factual_plm[:, :, 0].mean(axis=1)[-4], 'llama2 factual', color='red', verticalalignment='top')\n",
    "        text_factual2.set_path_effects(text_effect)\n",
    "\n",
    "        text_creative1 = ax.text(end_temp, scores_creative_chat[:, :, 0].mean(axis=1)[-4], 'llama2-chat creative', color='lightblue', verticalalignment='top', style='italic')\n",
    "        text_creative1.set_path_effects(text_effect)\n",
    "\n",
    "        text_creative2 = ax.text(end_temp, scores_creative_plm[:, :, 0].mean(axis=1)[-4], 'llama2 creative', color='salmon', verticalalignment='bottom', style='italic')\n",
    "        text_creative2.set_path_effects(text_effect)\n",
    "        i+=1\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(creative_factual_full_f, bbox_inches=\"tight\") \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368e4e9-90ad-4c54-bc0a-d3b128eb9202",
   "metadata": {},
   "source": [
    "## Plot the difference in diversity between creative and factual changes for llama2 and llama2-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c272bb-0862-45f8-8888-45c533cecf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_metrics = len(diversity_metrics.keys())\n",
    "fig, axes = plt.subplots(num_metrics, 2, figsize=(20, 5*num_metrics))\n",
    "# make font bigger\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "text_effect = [path_effects.withStroke(linewidth=3, foreground='white')]\n",
    "\n",
    "i=0\n",
    "for index, metric in enumerate(diversity_metrics.keys()):\n",
    "\n",
    "    for col_idx, result_chat in enumerate([llama2_chat_results_20_words, llama2_chat_results_5_words]):\n",
    "        ax = axes[index, col_idx]\n",
    "\n",
    "        scores_factual_chat = result_chat[\"factual\"][metric]\n",
    "        scores_creative_chat = result_chat[\"creative\"][metric]\n",
    "\n",
    "        result_plm = [llama2_results_20_words, llama2_results_5_words][col_idx]\n",
    "        scores_factual_plm = result_plm[\"factual\"][metric]\n",
    "        scores_creative_plm = result_plm[\"creative\"][metric]\n",
    "\n",
    "        # Calculate differences\n",
    "        diff_llamaa_chat = scores_creative_chat[:, :, 0] - scores_factual_chat[:, :, 0]\n",
    "        diff_llamaa_plm = scores_creative_plm[:, :, 0] - scores_factual_plm[:, :, 0]\n",
    "\n",
    "        # Plotting differences\n",
    "        ax.plot(temperatures, diff_llamaa_chat.mean(axis=1), label='llama2-chat', marker='o', color=\"blue\")\n",
    "        ax.fill_between(temperatures, diff_llamaa_chat.mean(axis=1) - 2 * diff_llamaa_chat.std(axis=1) / np.sqrt(diff_llamaa_chat.shape[1]), \n",
    "                        diff_llamaa_chat.mean(axis=1) + 2 * diff_llamaa_chat.std(axis=1) / np.sqrt(diff_llamaa_chat.shape[1]), alpha=0.2, color=\"blue\")\n",
    "\n",
    "        ax.plot(temperatures, diff_llamaa_plm.mean(axis=1), label='llama2', marker='o', color=\"red\")\n",
    "        ax.fill_between(temperatures, diff_llamaa_plm.mean(axis=1) - 2 * diff_llamaa_plm.std(axis=1) / np.sqrt(diff_llamaa_plm.shape[1]), \n",
    "                        diff_llamaa_plm.mean(axis=1) + 2 * diff_llamaa_plm.std(axis=1) / np.sqrt(diff_llamaa_plm.shape[1]), alpha=0.2, color=\"red\")\n",
    "\n",
    "        end_temp = temperatures[-4]\n",
    "        text_llama = ax.text(end_temp, diff_llamaa_chat.mean(axis=1)[-4], 'llama2-chat', color='blue', verticalalignment='bottom')\n",
    "        text_llama.set_path_effects(text_effect)\n",
    "\n",
    "        text_vicuna = ax.text(end_temp, diff_llamaa_plm.mean(axis=1)[-4], 'llama2', color='red', verticalalignment='top')\n",
    "        text_vicuna.set_path_effects(text_effect)\n",
    "\n",
    "        # ax.set_title(f\"Metric: {metric} for Result {20 if col_idx == 0 else 5} max words\")\n",
    "        ax.set_xlabel(\"Temperature\")\n",
    "        ax.set_ylabel(f\"Creative {metric} - Factual {metric}\")\n",
    "        i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4225185-9ec9-4729-bbea-193682753022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea800d-f1e6-417d-bbfd-f44d6b471957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
